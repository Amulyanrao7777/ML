{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj7ZAGVYKMWTkKQpibxAwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulyanrao7777/ML/blob/main/lab2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7jxoW6QhNW58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DecisionStump:\n",
        "    \"\"\"Simple decision stump (one-level decision tree) for AdaBoost\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.polarity = 1  # 1 if greater than threshold predicts +1, -1 otherwise\n",
        "        self.feature_name = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict using the stump rule\"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        predictions = np.ones(n_samples)\n",
        "\n",
        "        feature_values = X[:, self.feature_index]\n",
        "\n",
        "        if self.polarity == 1:\n",
        "            predictions[feature_values < self.threshold] = -1\n",
        "        else:\n",
        "            predictions[feature_values >= self.threshold] = -1\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def __repr__(self):\n",
        "        operator = \">=\" if self.polarity == 1 else \"<\"\n",
        "        return f\"If {self.feature_name} {operator} {self.threshold} → +1 (Yes), else -1 (No)\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoost:\n",
        "    \"\"\"AdaBoost classifier implementation\"\"\"\n",
        "\n",
        "    def __init__(self, n_estimators=5, verbose=True):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.stumps = []\n",
        "        self.alphas = []\n",
        "        self.verbose = verbose\n",
        "        self.training_history = []\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Train AdaBoost classifier\n",
        "\n",
        "        Parameters:\n",
        "        X: feature matrix (n_samples, n_features)\n",
        "        y: labels (+1 or -1)\n",
        "        feature_names: list of feature names for display\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize weights uniformly\n",
        "        weights = np.ones(n_samples) / n_samples\n",
        "\n",
        "        if feature_names is None:\n",
        "            feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
        "\n",
        "        for t in range(self.n_estimators):\n",
        "            if self.verbose:\n",
        "                print(f\"\\n{'='*80}\")\n",
        "                print(f\"ROUND {t+1}\")\n",
        "                print(f\"{'='*80}\")\n",
        "                print(f\"Current weights: {weights}\")\n",
        "\n",
        "            # Find best stump\n",
        "            stump, min_error, best_predictions = self._find_best_stump(\n",
        "                X, y, weights, feature_names\n",
        "            )\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"\\nBest stump: {stump}\")\n",
        "                print(f\"Weighted error: ε_{t+1} = {min_error:.4f}\")\n",
        "\n",
        "            # Check for perfect classifier\n",
        "            if min_error == 0:\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nPerfect classifier found! Error = 0\")\n",
        "                    print(f\"α_{t+1} → ∞, stopping AdaBoost\")\n",
        "                # Assign very large alpha for perfect classifier\n",
        "                alpha = 10.0\n",
        "                self.stumps.append(stump)\n",
        "                self.alphas.append(alpha)\n",
        "                break\n",
        "\n",
        "            # Check if error is too high (random guessing or worse)\n",
        "            if min_error >= 0.5:\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nError >= 0.5, stopping (weak learner not better than random)\")\n",
        "                break\n",
        "\n",
        "            # Calculate alpha (model weight)\n",
        "            alpha = 0.5 * np.log((1 - min_error) / (min_error + 1e-10))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"α_{t+1} = 0.5 × ln((1-{min_error:.4f})/{min_error:.4f}) = {alpha:.4f}\")\n",
        "                print(f\"e^(+α_{t+1}) ≈ {np.exp(alpha):.4f}\")\n",
        "                print(f\"e^(-α_{t+1}) ≈ {np.exp(-alpha):.4f}\")\n",
        "\n",
        "            # Update weights\n",
        "            weights = self._update_weights(weights, y, best_predictions, alpha)\n",
        "\n",
        "            if self.verbose:\n",
        "                self._print_weight_update(y, best_predictions, weights, alpha, t+1)\n",
        "\n",
        "            # Store stump and alpha\n",
        "            self.stumps.append(stump)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "            # Store history\n",
        "            self.training_history.append({\n",
        "                'round': t+1,\n",
        "                'stump': stump,\n",
        "                'alpha': alpha,\n",
        "                'error': min_error,\n",
        "                'weights': weights.copy()\n",
        "            })\n",
        "\n",
        "            # Check accuracy on training set\n",
        "            train_pred = self.predict(X)\n",
        "            train_acc = np.mean(train_pred == y)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nCumulative training accuracy after round {t+1}: {train_acc:.2%}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _find_best_stump(self, X, y, weights, feature_names):\n",
        "        \"\"\"Find the best decision stump (weak learner)\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        min_error = float('inf')\n",
        "        best_stump = None\n",
        "        best_predictions = None\n",
        "\n",
        "        # Try each feature\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = X[:, feature_idx]\n",
        "            unique_values = np.unique(feature_values)\n",
        "\n",
        "            # Try thresholds between unique values\n",
        "            thresholds = []\n",
        "            for i in range(len(unique_values)):\n",
        "                if i == 0:\n",
        "                    # Try threshold at minimum value\n",
        "                    thresholds.append(unique_values[i])\n",
        "                else:\n",
        "                    # Try threshold between consecutive values\n",
        "                    thresholds.append((unique_values[i-1] + unique_values[i]) / 2)\n",
        "\n",
        "            # Also try the exact unique values as thresholds\n",
        "            thresholds.extend(unique_values)\n",
        "            thresholds = np.unique(thresholds)\n",
        "\n",
        "            # Try each threshold with both polarities\n",
        "            for threshold in thresholds:\n",
        "                for polarity in [1, -1]:\n",
        "                    # Make predictions\n",
        "                    predictions = np.ones(n_samples)\n",
        "                    if polarity == 1:\n",
        "                        predictions[feature_values < threshold] = -1\n",
        "                    else:\n",
        "                        predictions[feature_values >= threshold] = -1\n",
        "\n",
        "                    # Calculate weighted error\n",
        "                    misclassified = predictions != y\n",
        "                    error = np.sum(weights[misclassified])\n",
        "\n",
        "                    # Update best stump if this is better\n",
        "                    if error < min_error:\n",
        "                        min_error = error\n",
        "                        best_stump = DecisionStump()\n",
        "                        best_stump.feature_index = feature_idx\n",
        "                        best_stump.threshold = threshold\n",
        "                        best_stump.polarity = polarity\n",
        "                        best_stump.feature_name = feature_names[feature_idx]\n",
        "                        best_predictions = predictions\n",
        "\n",
        "        return best_stump, min_error, best_predictions\n",
        "\n",
        "    def _update_weights(self, weights, y, predictions, alpha):\n",
        "        \"\"\"Update sample weights based on classification errors\"\"\"\n",
        "        # Calculate new weights: w_i * e^(-alpha * y_i * h(x_i))\n",
        "        new_weights = weights * np.exp(-alpha * y * predictions)\n",
        "\n",
        "        # Normalize weights to sum to 1\n",
        "        new_weights /= np.sum(new_weights)\n",
        "\n",
        "        return new_weights\n",
        "\n",
        "    def _print_weight_update(self, y, predictions, new_weights, alpha, round_num):\n",
        "        \"\"\"Print detailed weight update information\"\"\"\n",
        "        print(f\"\\nWeight updates for Round {round_num}:\")\n",
        "        print(f\"{'Row':<5} {'Correct?':<10} {'Update':<20} {'New Weight':<15}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for i in range(len(y)):\n",
        "            correct = \"✓\" if y[i] == predictions[i] else \"✗\"\n",
        "            multiplier = np.exp(-alpha) if y[i] == predictions[i] else np.exp(alpha)\n",
        "            update_str = f\"× {multiplier:.4f}\"\n",
        "            print(f\"{i+1:<5} {correct:<10} {update_str:<20} {new_weights[i]:.4f}\")\n",
        "\n",
        "        print(f\"\\nWeights sum: {np.sum(new_weights):.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions using the ensemble of stumps\"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        weighted_predictions = np.zeros(n_samples)\n",
        "\n",
        "        # Weighted voting\n",
        "        for stump, alpha in zip(self.stumps, self.alphas):\n",
        "            predictions = stump.predict(X)\n",
        "            weighted_predictions += alpha * predictions\n",
        "\n",
        "        # Return sign of weighted sum\n",
        "        return np.sign(weighted_predictions)\n",
        "\n",
        "    def predict_with_scores(self, X):\n",
        "        \"\"\"Return both predictions and weighted scores\"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        weighted_predictions = np.zeros(n_samples)\n",
        "\n",
        "        for stump, alpha in zip(self.stumps, self.alphas):\n",
        "            predictions = stump.predict(X)\n",
        "            weighted_predictions += alpha * predictions\n",
        "\n",
        "        return np.sign(weighted_predictions), weighted_predictions\n",
        "\n",
        "    def print_final_model(self):\n",
        "        \"\"\"Print the final ensemble model\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"FINAL ADABOOST MODEL\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"\\nNumber of weak learners: {len(self.stumps)}\")\n",
        "        print(f\"\\nH(x) = sign(\", end=\"\")\n",
        "\n",
        "        terms = []\n",
        "        for i, (stump, alpha) in enumerate(zip(self.stumps, self.alphas)):\n",
        "            terms.append(f\"{alpha:.4f} × h_{i+1}(x)\")\n",
        "        print(\" + \".join(terms) + \")\")\n",
        "\n",
        "        print(\"\\nWhere:\")\n",
        "        for i, stump in enumerate(self.stumps):\n",
        "            print(f\"  h_{i+1}(x): {stump}\")\n",
        "\n",
        "        print(f\"\\nTotal alpha weights by feature:\")\n",
        "        feature_weights = {}\n",
        "        for stump, alpha in zip(self.stumps, self.alphas):\n",
        "            fname = stump.feature_name\n",
        "            if fname in feature_weights:\n",
        "                feature_weights[fname] += alpha\n",
        "            else:\n",
        "                feature_weights[fname] = alpha\n",
        "\n",
        "        for fname, total_alpha in sorted(feature_weights.items(), key=lambda x: -x[1]):\n",
        "            print(f\"  {fname}: {total_alpha:.4f}\")"
      ],
      "metadata": {
        "id": "tv41I7K_PY9g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(df, target_col='Illness'):\n",
        "    \"\"\"Encode data for AdaBoost (convert target to +1/-1)\"\"\"\n",
        "    df_encoded = df.copy()\n",
        "    df_encoded[target_col] = df_encoded[target_col].map({'Yes': 1, 'No': -1})\n",
        "    return df_encoded"
      ],
      "metadata": {
        "id": "xOJQcrglPvFY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def example_1_perfect_classifier():\n",
        "    \"\"\"Example 1: Perfect classifier case (no noise)\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE 1: PERFECT CLASSIFIER (NO NOISE)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create dataset\n",
        "    data = {\n",
        "        'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "        'Age': [38, 52, 45, 29, 61],\n",
        "        'Income': [420000, 360000, 780000, 300000, 500000],\n",
        "        'Smoking': [0, 5, 0, 12, 8],\n",
        "        'Illness': ['No', 'Yes', 'No', 'Yes', 'Yes']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"\\nDataset:\")\n",
        "    print(df)\n",
        "\n",
        "    # Prepare data\n",
        "    df_encoded = encode_data(df)\n",
        "    X = df_encoded[['Age', 'Income', 'Smoking']].values\n",
        "    y = df_encoded['Illness'].values\n",
        "    feature_names = ['Age', 'Income', 'Smoking']\n",
        "\n",
        "    # Train AdaBoost\n",
        "    clf = AdaBoost(n_estimators=3, verbose=True)\n",
        "    clf.fit(X, y, feature_names)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = clf.predict(X)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FINAL PREDICTIONS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Row':<5} {'True y':<10} {'Predicted':<10} {'Correct?':<10}\")\n",
        "    print(\"-\" * 40)\n",
        "    for i in range(len(y)):\n",
        "        correct = \"✓\" if y[i] == predictions[i] else \"✗\"\n",
        "        print(f\"{i+1:<5} {y[i]:<10} {predictions[i]:<10} {correct:<10}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    print(f\"\\nFinal Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "    clf.print_final_model()"
      ],
      "metadata": {
        "id": "wQrXi4rMP_Ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def example_1_with_noise():\n",
        "    \"\"\"Example 1: With noise (Row 3 is ill non-smoker)\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE 1: WITH NOISE (ROW 3 MODIFIED)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create dataset with noise\n",
        "    data = {\n",
        "        'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "        'Age': [38, 52, 45, 29, 61],\n",
        "        'Income': [420000, 360000, 780000, 300000, 500000],\n",
        "        'Smoking': [0, 5, 0, 12, 8],\n",
        "        'Illness': ['No', 'Yes', 'Yes', 'Yes', 'Yes']  # Row 3 changed to Yes (noise)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"\\nDataset (with noise at Row 3):\")\n",
        "    print(df)\n",
        "\n",
        "    # Prepare data\n",
        "    df_encoded = encode_data(df)\n",
        "    X = df_encoded[['Age', 'Income', 'Smoking']].values\n",
        "    y = df_encoded['Illness'].values\n",
        "    feature_names = ['Age', 'Income', 'Smoking']\n",
        "\n",
        "    # Train AdaBoost for 3 rounds\n",
        "    clf = AdaBoost(n_estimators=3, verbose=True)\n",
        "    clf.fit(X, y, feature_names)\n",
        "\n",
        "    # Make predictions with scores\n",
        "    predictions, scores = clf.predict_with_scores(X)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FINAL PREDICTIONS WITH WEIGHTED SCORES\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Row':<5} {'True y':<10} {'Score':<15} {'Predicted':<10} {'Correct?':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i in range(len(y)):\n",
        "        correct = \"✓\" if y[i] == predictions[i] else \"✗\"\n",
        "        print(f\"{i+1:<5} {y[i]:<10} {scores[i]:<15.4f} {predictions[i]:<10} {correct:<10}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    print(f\"\\nAccuracy after 3 rounds: {accuracy:.2%}\")\n",
        "\n",
        "    clf.print_final_model()\n",
        "\n",
        "    return clf, X, y, feature_names"
      ],
      "metadata": {
        "id": "b0vktb44QDuz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def continue_rounds_4_5(clf, X, y, feature_names):\n",
        "    \"\"\"Continue with rounds 4 and 5 (homework)\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"HOMEWORK: ROUNDS 4 AND 5\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Continue training for 2 more rounds\n",
        "    clf_extended = AdaBoost(n_estimators=5, verbose=True)\n",
        "    clf_extended.fit(X, y, feature_names)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions, scores = clf_extended.predict_with_scores(X)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FINAL PREDICTIONS AFTER 5 ROUNDS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Row':<5} {'True y':<10} {'Score':<15} {'Predicted':<10} {'Correct?':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i in range(len(y)):\n",
        "        correct = \"✓\" if y[i] == predictions[i] else \"✗\"\n",
        "        print(f\"{i+1:<5} {y[i]:<10} {scores[i]:<15.4f} {predictions[i]:<10} {correct:<10}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    print(f\"\\nFinal Accuracy after 5 rounds: {accuracy:.2%}\")\n",
        "\n",
        "    clf_extended.print_final_model()\n",
        "\n",
        "\n",
        "def example_2():\n",
        "    \"\"\"Example 2: BMI dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE 2: BMI DATASET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create dataset\n",
        "    data = {\n",
        "        'Gender': ['Female', 'Male', 'Male', 'Female', 'Male'],\n",
        "        'Age': [33, 57, 41, 49, 36],\n",
        "        'Income': [480000, 320000, 900000, 540000, 450000],\n",
        "        'BMI': [22.1, 29.5, 24.0, 31.2, 27.8],\n",
        "        'Illness': ['No', 'Yes', 'No', 'Yes', 'No']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"\\nDataset:\")\n",
        "    print(df)\n",
        "\n",
        "    # Prepare data\n",
        "    df_encoded = encode_data(df)\n",
        "    X = df_encoded[['Age', 'Income', 'BMI']].values\n",
        "    y = df_encoded['Illness'].values\n",
        "    feature_names = ['Age', 'Income', 'BMI']\n",
        "\n",
        "    # Train AdaBoost\n",
        "    clf = AdaBoost(n_estimators=5, verbose=True)\n",
        "    clf.fit(X, y, feature_names)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions, scores = clf.predict_with_scores(X)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FINAL PREDICTIONS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'Row':<5} {'True y':<10} {'Score':<15} {'Predicted':<10} {'Correct?':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i in range(len(y)):\n",
        "        correct = \"✓\" if y[i] == predictions[i] else \"✗\"\n",
        "        print(f\"{i+1:<5} {y[i]:<10} {scores[i]:<15.4f} {predictions[i]:<10} {correct:<10}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    print(f\"\\nFinal Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "    clf.print_final_model()"
      ],
      "metadata": {
        "id": "MU7SAjWmQKRA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run Example 1 - Perfect Classifier\n",
        "    example_1_perfect_classifier()\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Run Example 1 - With Noise (3 rounds as in document)\n",
        "    clf, X, y, feature_names = example_1_with_noise()\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Continue with Rounds 4 and 5 (Homework)\n",
        "    continue_rounds_4_5(clf, X, y, feature_names)\n",
        "\n",
        "    print(\"\\n\\n\" + \"#\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Run Example 2 - BMI Dataset\n",
        "    example_2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYelY1kKQMrb",
        "outputId": "f6d9e2f5-5ad9-45e1-e83f-caef534b7dd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXAMPLE 1: PERFECT CLASSIFIER (NO NOISE)\n",
            "================================================================================\n",
            "\n",
            "Dataset:\n",
            "   Gender  Age  Income  Smoking Illness\n",
            "0    Male   38  420000        0      No\n",
            "1  Female   52  360000        5     Yes\n",
            "2    Male   45  780000        0      No\n",
            "3  Female   29  300000       12     Yes\n",
            "4    Male   61  500000        8     Yes\n",
            "\n",
            "================================================================================\n",
            "ROUND 1\n",
            "================================================================================\n",
            "Current weights: [0.2 0.2 0.2 0.2 0.2]\n",
            "\n",
            "Best stump: If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_1 = 0.0000\n",
            "\n",
            "Perfect classifier found! Error = 0\n",
            "α_1 → ∞, stopping AdaBoost\n",
            "\n",
            "================================================================================\n",
            "FINAL PREDICTIONS\n",
            "================================================================================\n",
            "Row   True y     Predicted  Correct?  \n",
            "----------------------------------------\n",
            "1     -1         -1.0       ✓         \n",
            "2     1          1.0        ✓         \n",
            "3     -1         -1.0       ✓         \n",
            "4     1          1.0        ✓         \n",
            "5     1          1.0        ✓         \n",
            "\n",
            "Final Accuracy: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL ADABOOST MODEL\n",
            "================================================================================\n",
            "\n",
            "Number of weak learners: 1\n",
            "\n",
            "H(x) = sign(10.0000 × h_1(x))\n",
            "\n",
            "Where:\n",
            "  h_1(x): If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "\n",
            "Total alpha weights by feature:\n",
            "  Smoking: 10.0000\n",
            "\n",
            "\n",
            "################################################################################\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 1: WITH NOISE (ROW 3 MODIFIED)\n",
            "================================================================================\n",
            "\n",
            "Dataset (with noise at Row 3):\n",
            "   Gender  Age  Income  Smoking Illness\n",
            "0    Male   38  420000        0      No\n",
            "1  Female   52  360000        5     Yes\n",
            "2    Male   45  780000        0     Yes\n",
            "3  Female   29  300000       12     Yes\n",
            "4    Male   61  500000        8     Yes\n",
            "\n",
            "================================================================================\n",
            "ROUND 1\n",
            "================================================================================\n",
            "Current weights: [0.2 0.2 0.2 0.2 0.2]\n",
            "\n",
            "Best stump: If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_1 = 0.2000\n",
            "α_1 = 0.5 × ln((1-0.2000)/0.2000) = 0.6931\n",
            "e^(+α_1) ≈ 2.0000\n",
            "e^(-α_1) ≈ 0.5000\n",
            "\n",
            "Weight updates for Round 1:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✗          × 2.0000             0.5000\n",
            "2     ✓          × 0.5000             0.1250\n",
            "3     ✓          × 0.5000             0.1250\n",
            "4     ✓          × 0.5000             0.1250\n",
            "5     ✓          × 0.5000             0.1250\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 1: 80.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 2\n",
            "================================================================================\n",
            "Current weights: [0.5   0.125 0.125 0.125 0.125]\n",
            "\n",
            "Best stump: If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_2 = 0.1250\n",
            "α_2 = 0.5 × ln((1-0.1250)/0.1250) = 0.9730\n",
            "e^(+α_2) ≈ 2.6458\n",
            "e^(-α_2) ≈ 0.3780\n",
            "\n",
            "Weight updates for Round 2:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✓          × 0.3780             0.2857\n",
            "2     ✓          × 0.3780             0.0714\n",
            "3     ✓          × 0.3780             0.0714\n",
            "4     ✗          × 2.6458             0.5000\n",
            "5     ✓          × 0.3780             0.0714\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 2: 80.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 3\n",
            "================================================================================\n",
            "Current weights: [0.28571429 0.07142857 0.07142857 0.5        0.07142857]\n",
            "\n",
            "Best stump: If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_3 = 0.0714\n",
            "α_3 = 0.5 × ln((1-0.0714)/0.0714) = 1.2825\n",
            "e^(+α_3) ≈ 3.6056\n",
            "e^(-α_3) ≈ 0.2774\n",
            "\n",
            "Weight updates for Round 3:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✓          × 0.2774             0.1538\n",
            "2     ✓          × 0.2774             0.0385\n",
            "3     ✗          × 3.6056             0.5000\n",
            "4     ✓          × 0.2774             0.2692\n",
            "5     ✓          × 0.2774             0.0385\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 3: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL PREDICTIONS WITH WEIGHTED SCORES\n",
            "================================================================================\n",
            "Row   True y     Score           Predicted  Correct?  \n",
            "------------------------------------------------------------\n",
            "1     -1         -1.5623         -1.0       ✓         \n",
            "2     1          2.9486          1.0        ✓         \n",
            "3     1          0.3836          1.0        ✓         \n",
            "4     1          1.0027          1.0        ✓         \n",
            "5     1          2.9486          1.0        ✓         \n",
            "\n",
            "Accuracy after 3 rounds: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL ADABOOST MODEL\n",
            "================================================================================\n",
            "\n",
            "Number of weak learners: 3\n",
            "\n",
            "H(x) = sign(0.6931 × h_1(x) + 0.9730 × h_2(x) + 1.2825 × h_3(x))\n",
            "\n",
            "Where:\n",
            "  h_1(x): If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "  h_2(x): If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "  h_3(x): If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "\n",
            "Total alpha weights by feature:\n",
            "  Age: 1.6661\n",
            "  Smoking: 1.2825\n",
            "\n",
            "\n",
            "################################################################################\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "HOMEWORK: ROUNDS 4 AND 5\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ROUND 1\n",
            "================================================================================\n",
            "Current weights: [0.2 0.2 0.2 0.2 0.2]\n",
            "\n",
            "Best stump: If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_1 = 0.2000\n",
            "α_1 = 0.5 × ln((1-0.2000)/0.2000) = 0.6931\n",
            "e^(+α_1) ≈ 2.0000\n",
            "e^(-α_1) ≈ 0.5000\n",
            "\n",
            "Weight updates for Round 1:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✗          × 2.0000             0.5000\n",
            "2     ✓          × 0.5000             0.1250\n",
            "3     ✓          × 0.5000             0.1250\n",
            "4     ✓          × 0.5000             0.1250\n",
            "5     ✓          × 0.5000             0.1250\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 1: 80.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 2\n",
            "================================================================================\n",
            "Current weights: [0.5   0.125 0.125 0.125 0.125]\n",
            "\n",
            "Best stump: If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_2 = 0.1250\n",
            "α_2 = 0.5 × ln((1-0.1250)/0.1250) = 0.9730\n",
            "e^(+α_2) ≈ 2.6458\n",
            "e^(-α_2) ≈ 0.3780\n",
            "\n",
            "Weight updates for Round 2:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✓          × 0.3780             0.2857\n",
            "2     ✓          × 0.3780             0.0714\n",
            "3     ✓          × 0.3780             0.0714\n",
            "4     ✗          × 2.6458             0.5000\n",
            "5     ✓          × 0.3780             0.0714\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 2: 80.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 3\n",
            "================================================================================\n",
            "Current weights: [0.28571429 0.07142857 0.07142857 0.5        0.07142857]\n",
            "\n",
            "Best stump: If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_3 = 0.0714\n",
            "α_3 = 0.5 × ln((1-0.0714)/0.0714) = 1.2825\n",
            "e^(+α_3) ≈ 3.6056\n",
            "e^(-α_3) ≈ 0.2774\n",
            "\n",
            "Weight updates for Round 3:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✓          × 0.2774             0.1538\n",
            "2     ✓          × 0.2774             0.0385\n",
            "3     ✗          × 3.6056             0.5000\n",
            "4     ✓          × 0.2774             0.2692\n",
            "5     ✓          × 0.2774             0.0385\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 3: 100.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 4\n",
            "================================================================================\n",
            "Current weights: [0.15384615 0.03846154 0.5        0.26923077 0.03846154]\n",
            "\n",
            "Best stump: If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_4 = 0.1538\n",
            "α_4 = 0.5 × ln((1-0.1538)/0.1538) = 0.8524\n",
            "e^(+α_4) ≈ 2.3452\n",
            "e^(-α_4) ≈ 0.4264\n",
            "\n",
            "Weight updates for Round 4:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✗          × 2.3452             0.5000\n",
            "2     ✓          × 0.4264             0.0227\n",
            "3     ✓          × 0.4264             0.2955\n",
            "4     ✓          × 0.4264             0.1591\n",
            "5     ✓          × 0.4264             0.0227\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 4: 100.00%\n",
            "\n",
            "================================================================================\n",
            "ROUND 5\n",
            "================================================================================\n",
            "Current weights: [0.5        0.02272727 0.29545455 0.15909091 0.02272727]\n",
            "\n",
            "Best stump: If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_5 = 0.1591\n",
            "α_5 = 0.5 × ln((1-0.1591)/0.1591) = 0.8325\n",
            "e^(+α_5) ≈ 2.2991\n",
            "e^(-α_5) ≈ 0.4350\n",
            "\n",
            "Weight updates for Round 5:\n",
            "Row   Correct?   Update               New Weight     \n",
            "------------------------------------------------------------\n",
            "1     ✓          × 0.4350             0.2973\n",
            "2     ✓          × 0.4350             0.0135\n",
            "3     ✓          × 0.4350             0.1757\n",
            "4     ✗          × 2.2991             0.5000\n",
            "5     ✓          × 0.4350             0.0135\n",
            "\n",
            "Weights sum: 1.0000\n",
            "\n",
            "Cumulative training accuracy after round 5: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL PREDICTIONS AFTER 5 ROUNDS\n",
            "================================================================================\n",
            "Row   True y     Score           Predicted  Correct?  \n",
            "------------------------------------------------------------\n",
            "1     -1         -1.5424         -1.0       ✓         \n",
            "2     1          4.6335          1.0        ✓         \n",
            "3     1          2.0685          1.0        ✓         \n",
            "4     1          1.0225          1.0        ✓         \n",
            "5     1          4.6335          1.0        ✓         \n",
            "\n",
            "Final Accuracy after 5 rounds: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL ADABOOST MODEL\n",
            "================================================================================\n",
            "\n",
            "Number of weak learners: 5\n",
            "\n",
            "H(x) = sign(0.6931 × h_1(x) + 0.9730 × h_2(x) + 1.2825 × h_3(x) + 0.8524 × h_4(x) + 0.8325 × h_5(x))\n",
            "\n",
            "Where:\n",
            "  h_1(x): If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "  h_2(x): If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "  h_3(x): If Smoking >= 2.5 → +1 (Yes), else -1 (No)\n",
            "  h_4(x): If Age >= 29.0 → +1 (Yes), else -1 (No)\n",
            "  h_5(x): If Age >= 41.5 → +1 (Yes), else -1 (No)\n",
            "\n",
            "Total alpha weights by feature:\n",
            "  Age: 3.3510\n",
            "  Smoking: 1.2825\n",
            "\n",
            "\n",
            "################################################################################\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 2: BMI DATASET\n",
            "================================================================================\n",
            "\n",
            "Dataset:\n",
            "   Gender  Age  Income   BMI Illness\n",
            "0  Female   33  480000  22.1      No\n",
            "1    Male   57  320000  29.5     Yes\n",
            "2    Male   41  900000  24.0      No\n",
            "3  Female   49  540000  31.2     Yes\n",
            "4    Male   36  450000  27.8      No\n",
            "\n",
            "================================================================================\n",
            "ROUND 1\n",
            "================================================================================\n",
            "Current weights: [0.2 0.2 0.2 0.2 0.2]\n",
            "\n",
            "Best stump: If Age >= 45.0 → +1 (Yes), else -1 (No)\n",
            "Weighted error: ε_1 = 0.0000\n",
            "\n",
            "Perfect classifier found! Error = 0\n",
            "α_1 → ∞, stopping AdaBoost\n",
            "\n",
            "================================================================================\n",
            "FINAL PREDICTIONS\n",
            "================================================================================\n",
            "Row   True y     Score           Predicted  Correct?  \n",
            "------------------------------------------------------------\n",
            "1     -1         -10.0000        -1.0       ✓         \n",
            "2     1          10.0000         1.0        ✓         \n",
            "3     -1         -10.0000        -1.0       ✓         \n",
            "4     1          10.0000         1.0        ✓         \n",
            "5     -1         -10.0000        -1.0       ✓         \n",
            "\n",
            "Final Accuracy: 100.00%\n",
            "\n",
            "================================================================================\n",
            "FINAL ADABOOST MODEL\n",
            "================================================================================\n",
            "\n",
            "Number of weak learners: 1\n",
            "\n",
            "H(x) = sign(10.0000 × h_1(x))\n",
            "\n",
            "Where:\n",
            "  h_1(x): If Age >= 45.0 → +1 (Yes), else -1 (No)\n",
            "\n",
            "Total alpha weights by feature:\n",
            "  Age: 10.0000\n"
          ]
        }
      ]
    }
  ]
}